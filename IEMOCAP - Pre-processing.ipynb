{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process IEMOCAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Extract Label Transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import pickle\n",
    "\n",
    "from util import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_folder('../FY Project/My Project/data/processed/IEMOCAP')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_file = '../My Project/data/processed/IEMOCAP/processed_tran.csv'\n",
    "out_file_trans = '../My Project/data/processed/IEMOCAP/sentence_only.txt'\n",
    "os.system('rm ' + out_file)  # Remove out file if it exists\n",
    "os.system('rm ' + out_file_trans)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_transcript(list_files, out_file, out_file_trans, test_data=False):\n",
    "    '''\n",
    "    Extracts transcript for each uniques session.\n",
    "\n",
    "        Parameters:\n",
    "            list_files (list): A list of files (with fullnames) to process transcript\n",
    "            out_file (string): Out file to write processed transcript\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "    '''\n",
    "    file_lines = []\n",
    "\n",
    "    if test_data:\n",
    "        out_file = out_file[:-4] + '_TESTDATA' + out_file[-4:]\n",
    "        out_file_trans = out_file_trans[:-4] + \\\n",
    "            '_TESTDATA' + out_file_trans[-4:]\n",
    "\n",
    "    for file in list_files: # Processes each file in file list\n",
    "\n",
    "        with open(file, 'r') as in_file:\n",
    "            file_lines = in_file.readlines()\n",
    "\n",
    "        with open(out_file, 'a') as outfile:\n",
    "            csv_writer = csv.writer(outfile)\n",
    "            file_lines = sorted(file_lines)\n",
    "\n",
    "            for line in file_lines:\n",
    "                line_split = line.split(':')\n",
    "\n",
    "                # Select session name i.e. (Ses01F_impro01_F000)\n",
    "                name = line_split[0].split(' ')[0].strip()\n",
    "\n",
    "                # Unwanted case\n",
    "                if name[:3] != 'Ses':\n",
    "                    continue\n",
    "                elif name[-3:-1] == 'XX':\n",
    "                    continue\n",
    "                \n",
    "                transcript = line_split[1].strip()\n",
    "\n",
    "                # cnt += 1\n",
    "                csv_writer.writerow([name, transcript])\n",
    "\n",
    "                with open(out_file_trans, 'a') as outfile_trans:\n",
    "                    outfile_trans.write(transcript + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_files = []\n",
    "\n",
    "for x in range(1, 5):\n",
    "    sess_title = 'Session' + str(x)\n",
    "\n",
    "    path = f'./data/raw/IEMOCAP_full_release/{sess_title}/dialog/transcriptions'\n",
    "\n",
    "    file_search(path, list_files)\n",
    "    list_files = sorted(list_files)\n",
    "\n",
    "    print(f\"{sess_title}, # Num of files: {len(list_files)}\")\n",
    "\n",
    "extract_transcript(list_files, out_file, out_file_trans)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 - Extract Transcript (Test Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_files = []\n",
    "\n",
    "for x in range(5, 6):\n",
    "    sess_title = 'Session' + str(x)\n",
    "\n",
    "    path = f'./data/raw/IEMOCAP_full_release/{sess_title}/dialog/transcriptions'\n",
    "\n",
    "    file_search(path, list_files)\n",
    "    list_files = sorted(list_files)\n",
    "\n",
    "    print(f\"{sess_title}, # Num of files: {len(list_files)}\")\n",
    "\n",
    "extract_transcript(list_files, out_file, out_file_trans, test_data=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Extract Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_file = '../My Project/data/processed/IEMOCAP/label.csv'\n",
    "os.system('rm ' + out_file)  # Remove out file if it exists\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_list = ['ang', 'hap', 'sad', 'neu', 'fru', 'exc', 'fea', 'sur', 'dis', 'oth', 'xxx']\n",
    "category = {}\n",
    "\n",
    "for cat_type in category_list:\n",
    "    if cat_type in category:\n",
    "        continue\n",
    "    else:\n",
    "        category[cat_type] = len(category)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_category(lines):\n",
    "    '''\n",
    "    Find ground truth category for each session recording in txt file.\n",
    "\n",
    "        Parameters:\n",
    "            lines (list): Lines extracted from each sessions Emoevaluation txt file\n",
    "\n",
    "        Returns:\n",
    "            cat_emo_list (list): List contains each Session name with groud-truth emotion \\\n",
    "                i.e. [['Ses01F_impro01_F000, 'neu']]\n",
    "\n",
    "    '''\n",
    "    cat_emo_list = []\n",
    "    is_target_line = True\n",
    "\n",
    "    for line in lines:\n",
    "\n",
    "        # Check if line is in format --> [START_TIME - END_TIME] TURN_NAME EMOTION [V, A, D]\n",
    "        if is_target_line == True:\n",
    "\n",
    "            try:\n",
    "                line_split = line.split('\\t')\n",
    "\n",
    "                session_id = line_split[1].strip()\n",
    "                cat_label = line_split[2].strip()\n",
    "\n",
    "                if cat_label not in category:  # Confirm cat_label is in category dictionary\n",
    "                    print(f'Invalid key --> {cat_label}')\n",
    "                    sys.exit()  # Exit script\n",
    "\n",
    "                cat_emo_list.append([session_id, cat_label])\n",
    "                is_target_line = False  # Subsequent lines are not target line i.e. C-E2:\tNeutral;\t()\n",
    "\n",
    "            except:\n",
    "                print(f'ERROR --> {line}')  # Error encontered on line\n",
    "                sys.exit()\n",
    "\n",
    "        else:\n",
    "            if line == '\\n':\n",
    "                is_target_line = True\n",
    "\n",
    "    return cat_emo_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_labels(list_files, out_file, test_data=False):\n",
    "    '''\n",
    "    Extracts labels for each unique session.\n",
    "\n",
    "        Parameters:\n",
    "            list_files (list): A list of files (with fullnames) to process transcript\n",
    "            out_file (string): Out file to write processed transcript\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "    '''\n",
    "    lines = []\n",
    "    sorted_cat_emo_list = []\n",
    "\n",
    "    if test_data:\n",
    "        out_file = out_file[:-4] + '_TESTDATA' + out_file[-4:]\n",
    "    \n",
    "    for file in list_files:\n",
    "\n",
    "        with open(file, 'r') as in_file:\n",
    "            lines = in_file.readlines()\n",
    "\n",
    "            # Remove header --> '% [START_TIME - END_TIME] TURN_NAME EMOTION [V, A, D]'\n",
    "            lines = lines[2:]\n",
    "            cat_emo_list = find_category(lines)\n",
    "\n",
    "        sorted_cat_emo_list = sorted(cat_emo_list)\n",
    "\n",
    "        with open(out_file, 'a') as outfile:\n",
    "            csv_writer = csv.writer(outfile)\n",
    "            csv_writer.writerows(sorted_cat_emo_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_files = []\n",
    "skip_dir = ['Attribute', 'Categorical', 'Self-evaluation']\n",
    "\n",
    "for x in range(1, 5):\n",
    "    sess_title = 'Session' + str(x)\n",
    "\n",
    "    path = f'./data/raw/IEMOCAP_full_release/{sess_title}/dialog/EmoEvaluation/'\n",
    "    file_search(path, list_files, skip_dir)\n",
    "    list_files = sorted(list_files)\n",
    "\n",
    "    print(f\"{sess_title}, # Num of files: {len(list_files)}\")\n",
    "\n",
    "extract_labels(list_files, out_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 - Extract Label (Test Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_files = []\n",
    "skip_dir = ['Attribute', 'Categorical', 'Self-evaluation']\n",
    "\n",
    "for x in range(5, 6):\n",
    "    sess_title = 'Session' + str(x)\n",
    "\n",
    "    path = f'./data/raw/IEMOCAP_full_release/{sess_title}/dialog/EmoEvaluation/'\n",
    "    file_search(path, list_files, skip_dir)\n",
    "    list_files = sorted(list_files)\n",
    "\n",
    "    print(f\"{sess_title}, # Num of files: {len(list_files)}\")\n",
    "\n",
    "extract_labels(list_files, out_file, test_data=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Process Extracted data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracted Data\n",
    "\n",
    "| Category \t| Session 1 - 4 \t| Session 5 \t|       \t|\n",
    "|----------\t|---------------\t|-----------\t|-------\t|\n",
    "| Angry    \t| 933           \t| 170       \t| 1103  \t|\n",
    "| Happy    \t| 1194          \t| 442       \t| 1636  \t|\n",
    "| Sad      \t| 839           \t| 245       \t| 1084  \t|\n",
    "| Neutral  \t| 1324          \t| 384       \t| 1708  \t|\n",
    "| Total    \t| 4290          \t| 1241      \t| 5531  \t|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = [] \n",
    "with open('./data/processed/IEMOCAP/label.csv', 'r') as f:\n",
    "    csv_reader = csv.reader(f)\n",
    "    lines = [line for line in csv_reader if len(line) > 0]\n",
    "\n",
    "print(len(lines))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 - Process Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/processed/IEMOCAP/processed_label.txt', 'w') as f:\n",
    "\n",
    "    with open('./data/processed/IEMOCAP/processed_ids.txt', 'w') as f2:\n",
    "\n",
    "        for line in lines:\n",
    "            if line[1] == 'ang':\n",
    "                f.write('ang\\n')\n",
    "                f2.write(line[0]+'\\n')\n",
    "            elif line[1] == 'hap':\n",
    "                f.write('hap\\n')\n",
    "                f2.write(line[0]+'\\n')\n",
    "            elif line[1] == 'exc':\n",
    "                f.write('hap\\n')\n",
    "                f2.write(line[0]+'\\n')\n",
    "            elif line[1] == 'sad':\n",
    "                f.write('sad\\n')\n",
    "                f2.write(line[0]+'\\n')\n",
    "            elif line[1] == 'neu':\n",
    "                f.write('neu\\n')\n",
    "                f2.write(line[0]+'\\n')\n",
    "            else:\n",
    "                f.write('-1\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = []\n",
    "with open('./data/processed/IEMOCAP/processed_label.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "lines = [line.strip() for line in lines]\n",
    "\n",
    "print('Angry (0)\\t-->', len([x for x in lines if x == 'ang']))\n",
    "print('Happy (1)\\t-->', len([x for x in lines if x == 'hap']))\n",
    "print('Sad (2)\\t\\t-->', len([x for x in lines if x == 'sad']))\n",
    "print('Neutral (3)\\t-->', len([x for x in lines if x == 'neu']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1.1 - Convert labels to four categories ['ang', 'hap', 'sad', 'neu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/processed/IEMOCAP/final/text/train/FC_label.txt', 'w') as f:\n",
    "    for label in lines:\n",
    "        if label != '-1':\n",
    "            f.write(label+'\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1.2 - Get sentences for four categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "\n",
    "with open('./data/processed/IEMOCAP/sentence_only.txt') as f:\n",
    "    full_sentences = f.readlines()\n",
    "\n",
    "sentences = [x.strip() for x in full_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/processed/IEMOCAP/final/text/train/FC_sentence.txt', 'w') as f:\n",
    "    for index, label in enumerate(lines):\n",
    "        if label != '-1':\n",
    "            f.write(sentences[index]+'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences, label = [], []\n",
    "\n",
    "with open('./data/processed/IEMOCAP/final/text/train/FC_sentence.txt') as f:\n",
    "    with open('./data/processed/IEMOCAP/final/text/train/FC_label.txt') as f2:\n",
    "        full_sentences = f.readlines()\n",
    "        category = f2.readlines()\n",
    "\n",
    "sentences = [x.strip() for x in full_sentences]\n",
    "label = [y.strip() for y in category]\n",
    "\n",
    "# sentences, label = shuffle_dataset(sentences, label)\n",
    "\n",
    "print(f'Sentence length --> {len(sentences)}, Label length --> {len(label)}')\n",
    "\n",
    "data_dict = {'sentences': sentences, 'label': label}\n",
    "train_dataset = pd.DataFrame.from_dict(data_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 - Process Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = [] \n",
    "with open('./data/processed/IEMOCAP/label_TESTDATA.csv', 'r') as f:\n",
    "    csv_reader = csv.reader(f)\n",
    "    lines = [line for line in csv_reader if len(line) > 0]\n",
    "\n",
    "print(len(lines))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/processed/IEMOCAP/processed_label_TESTDATA.txt', 'w') as f:\n",
    "\n",
    "    with open('./data/processed/IEMOCAP/processed_ids_TESTDATA.txt', 'w') as f2:\n",
    "\n",
    "        for line in lines:\n",
    "            if line[1] == 'ang':\n",
    "                f.write('ang\\n')\n",
    "                f2.write(line[0]+'\\n')\n",
    "            elif line[1] == 'hap':\n",
    "                f.write('hap\\n')\n",
    "                f2.write(line[0]+'\\n')\n",
    "            elif line[1] == 'exc':\n",
    "                f.write('hap\\n')\n",
    "                f2.write(line[0]+'\\n')\n",
    "            elif line[1] == 'sad':\n",
    "                f.write('sad\\n')\n",
    "                f2.write(line[0]+'\\n')\n",
    "            elif line[1] == 'neu':\n",
    "                f.write('neu\\n')\n",
    "                f2.write(line[0]+'\\n')\n",
    "            else:\n",
    "                f.write('-1\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = []\n",
    "with open('./data/processed/IEMOCAP/processed_label_TESTDATA.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "lines = [line.strip() for line in lines]\n",
    "\n",
    "print('Angry (0)\\t-->', len([x for x in lines if x == 'ang']))\n",
    "print('Happy (1)\\t-->', len([x for x in lines if x == 'hap']))\n",
    "print('Sad (2)\\t\\t-->', len([x for x in lines if x == 'sad']))\n",
    "print('Neutral (3)\\t-->', len([x for x in lines if x == 'neu']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2.1 - Convert labels to four categories ['ang', 'hap', 'sad', 'neu'] (Testdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/processed/IEMOCAP/final/text/test/FC_label_TESTDATA.txt', 'w') as f:\n",
    "    for label in lines:\n",
    "        if label != '-1':\n",
    "            f.write(label+'\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2.2 - Get sentences for four categories (Testdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "\n",
    "with open('./data/processed/IEMOCAP/sentence_only.txt') as f:\n",
    "    full_sentences = f.readlines()\n",
    "\n",
    "sentences = [x.strip() for x in full_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/processed/IEMOCAP/final/text/test/FC_sentence_TESTDATA.txt', 'w') as f:\n",
    "    for index, label in enumerate(lines):\n",
    "        if label != '-1':\n",
    "            f.write(sentences[index]+'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences, label = [], []\n",
    "\n",
    "with open('./data/processed/IEMOCAP/final/text/test/FC_label_TESTDATA.txt') as f:\n",
    "    with open('./data/processed/IEMOCAP/final/text/test/FC_label_TESTDATA.txt') as f2:\n",
    "        full_sentences = f.readlines()\n",
    "        category = f2.readlines()\n",
    "\n",
    "sentences = [x.strip() for x in full_sentences]\n",
    "label = [y.strip() for y in category]\n",
    "\n",
    "# sentences, label = shuffle_dataset(sentences, label)\n",
    "\n",
    "print(f'Sentence length --> {len(sentences)}, Label length --> {len(label)}')\n",
    "\n",
    "data_dict = {'sentences': sentences, 'label': label}\n",
    "test_dataset = pd.DataFrame.from_dict(data_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Save Dataframes as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.to_pickle('./data/processed/IEMOCAP/final/text/train/train_dataset.pkl')\n",
    "test_dataset.to_pickle('./data/processed/IEMOCAP/final/text/test/test_dataset.pkl')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Rakibul_Hassan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
